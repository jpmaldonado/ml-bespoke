{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5235ac00",
   "metadata": {},
   "source": [
    "# Inference with `pipeline`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "009562b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "C:\\Users\\HP\\Desktop\\ml-bespoke\\env\\lib\\site-packages\\torch\\storage.py:234: UserWarning: Failed to initialize NumPy: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem . (Triggered internally at ..\\torch\\csrc\\utils\\tensor_numpy.cpp:84.)\n",
      "  return super().__getitem__(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "text_class = pipeline(task=\"sentiment-analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ac04bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#text_class('we love you')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4acc6c9b",
   "metadata": {},
   "source": [
    "# Text classification\n",
    "https://huggingface.co/docs/transformers/tasks/sequence_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e55ecb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ro_sent = load_dataset(\"ro_sent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a414d201",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'original_id': '0',\n",
       " 'id': '0',\n",
       " 'sentence': 'acest document mi-a deschis cu adevarat ochii la ceea ce oamenii din afara statelor unite s-au gandit la atacurile din 11 septembrie. acest film a fost construit in mod expert si prezinta acest dezastru ca fiind mai mult decat un atac asupra pamantului american. urmarile acestui dezastru sunt previzionate din multe tari si perspective diferite. cred ca acest film ar trebui sa fie mai bine distribuit pentru acest punct. de asemenea, el ajuta in procesul de vindecare sa vada in cele din urma altceva decat stirile despre atacurile teroriste. si unele dintre piese sunt de fapt amuzante, dar nu abuziv asa. acest film a fost extrem de recomandat pentru mine, si am trecut pe acelasi sentiment.',\n",
       " 'label': 1}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ro_sent[\"train\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b078d4c",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5dbb5508",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb0fb4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"sentence\"], truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8561bec0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c7cd18d6ca1419f8760f2de3f300bb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/11005 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_ro_sent = ro_sent.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19051531",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3368d455ce754e6783f63ed5df8164bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import evaluate\n",
    "\n",
    "accuracy = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61c00541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: evaluate in c:\\users\\hp\\desktop\\ml-bespoke\\env\\lib\\site-packages (0.4.0)\n",
      "Requirement already satisfied: datasets>=2.0.0 in c:\\users\\hp\\desktop\\ml-bespoke\\env\\lib\\site-packages (from evaluate) (2.14.5)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\hp\\desktop\\ml-bespoke\\env\\lib\\site-packages (from evaluate) (1.22.3)\n",
      "Requirement already satisfied: dill in c:\\users\\hp\\desktop\\ml-bespoke\\env\\lib\\site-packages (from evaluate) (0.3.7)\n",
      "Requirement already satisfied: pandas in c:\\users\\hp\\desktop\\ml-bespoke\\env\\lib\\site-packages (from evaluate) (1.4.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\hp\\desktop\\ml-bespoke\\env\\lib\\site-packages (from evaluate) (2.27.1)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\hp\\desktop\\ml-bespoke\\env\\lib\\site-packages (from evaluate) (4.64.0)\n",
      "Requirement already satisfied: xxhash in c:\\users\\hp\\desktop\\ml-bespoke\\env\\lib\\site-packages (from evaluate) (3.3.0)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\hp\\desktop\\ml-bespoke\\env\\lib\\site-packages (from evaluate) (0.70.15)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in c:\\users\\hp\\desktop\\ml-bespoke\\env\\lib\\site-packages (from evaluate) (2023.6.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in c:\\users\\hp\\desktop\\ml-bespoke\\env\\lib\\site-packages (from evaluate) (0.17.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\hp\\desktop\\ml-bespoke\\env\\lib\\site-packages (from evaluate) (21.3)\n",
      "Requirement already satisfied: responses<0.19 in c:\\users\\hp\\desktop\\ml-bespoke\\env\\lib\\site-packages (from evaluate) (0.18.0)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in c:\\users\\hp\\desktop\\ml-bespoke\\env\\lib\\site-packages (from datasets>=2.0.0->evaluate) (9.0.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\hp\\desktop\\ml-bespoke\\env\\lib\\site-packages (from datasets>=2.0.0->evaluate) (3.8.5)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\hp\\desktop\\ml-bespoke\\env\\lib\\site-packages (from datasets>=2.0.0->evaluate) (6.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\hp\\desktop\\ml-bespoke\\env\\lib\\site-packages (from huggingface-hub>=0.7.0->evaluate) (3.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\hp\\desktop\\ml-bespoke\\env\\lib\\site-packages (from huggingface-hub>=0.7.0->evaluate) (4.7.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\hp\\desktop\\ml-bespoke\\env\\lib\\site-packages (from packaging->evaluate) (3.0.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\hp\\desktop\\ml-bespoke\\env\\lib\\site-packages (from requests>=2.19.0->evaluate) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\desktop\\ml-bespoke\\env\\lib\\site-packages (from requests>=2.19.0->evaluate) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\hp\\desktop\\ml-bespoke\\env\\lib\\site-packages (from requests>=2.19.0->evaluate) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\desktop\\ml-bespoke\\env\\lib\\site-packages (from requests>=2.19.0->evaluate) (3.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\desktop\\ml-bespoke\\env\\lib\\site-packages (from tqdm>=4.62.1->evaluate) (0.4.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\hp\\desktop\\ml-bespoke\\env\\lib\\site-packages (from pandas->evaluate) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\hp\\desktop\\ml-bespoke\\env\\lib\\site-packages (from pandas->evaluate) (2022.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\hp\\desktop\\ml-bespoke\\env\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (21.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\hp\\desktop\\ml-bespoke\\env\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\hp\\desktop\\ml-bespoke\\env\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\hp\\desktop\\ml-bespoke\\env\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\hp\\desktop\\ml-bespoke\\env\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\hp\\desktop\\ml-bespoke\\env\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hp\\desktop\\ml-bespoke\\env\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->evaluate) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42fee192",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eef69531",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {0: \"NEGATIVE\", 1: \"POSITIVE\"}\n",
    "label2id = {\"NEGATIVE\": 0, \"POSITIVE\": 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e81ebce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'classifier.weight', 'classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"distilbert-base-uncased\", num_labels=2, id2label=id2label, label2id=label2id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d628c0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_args = TrainingArguments(\"ro-sent-model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "401c4c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3c7fb310",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=train_args,\n",
    "    train_dataset=tokenized_ro_sent[\"train\"],\n",
    "    eval_dataset=tokenized_ro_sent[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    #data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f9e082",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='37' max='6729' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  37/6729 04:34 < 14:33:57, 0.13 it/s, Epoch 0.02/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb4aa4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
